{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths to all CSVs\n",
    "csv_paths = {\n",
    "    year: f\"C:/Users/Akshiya George/OneDrive/Desktop/Data Science/Amazon/amazon_india_{year}.csv\"\n",
    "    for year in range(2015, 2026)\n",
    "}\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Akshiya13\",\n",
    "    database=\"amazon\",\n",
    "    allow_local_infile=True\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Enable local infile\n",
    "cursor.execute(\"SET GLOBAL local_infile = 1;\")\n",
    "\n",
    "# Function to save temp CSV and load into MySQL\n",
    "def load_table(df, table_name):\n",
    "    temp_path = f\"{table_name}_temp.csv\"\n",
    "    df.to_csv(temp_path, index=False)\n",
    "    query = f\"\"\"\n",
    "    LOAD DATA LOCAL INFILE '{temp_path.replace(\"\\\\\", \"/\")}'\n",
    "    INTO TABLE {table_name}\n",
    "    FIELDS TERMINATED BY ',' \n",
    "    ENCLOSED BY '\"'\n",
    "    LINES TERMINATED BY '\\n'\n",
    "    IGNORE 1 ROWS;\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    os.remove(temp_path)\n",
    "    print(f\"‚úÖ Loaded {table_name}\")\n",
    "\n",
    "# Process each file\n",
    "for year, path in csv_paths.items():\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Extract and deduplicate\n",
    "    transactions = df[[\n",
    "        'transaction_id', 'order_date', 'customer_id', 'product_id',\n",
    "        'original_price_inr', 'discount_percent', 'discounted_price_inr',\n",
    "        'quantity', 'subtotal_inr', 'delivery_charges', 'final_amount_inr',\n",
    "        'payment_method', 'payment_method_cleaned', 'delivery_days',\n",
    "        'delivery_type', 'is_prime_member', 'is_festival_sale', 'festival_name',\n",
    "        'customer_rating', 'return_status', 'order_month', 'order_year',\n",
    "        'order_quarter', 'dup_key', 'dup_count', 'dup_status', 'flag_for_review'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    products = df[[\n",
    "        'product_id', 'product_name', 'category', 'subcategory', 'brand',\n",
    "        'product_weight_kg', 'is_prime_eligible', 'product_rating'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    customers = df[[\n",
    "        'customer_id', 'customer_city', 'customer_state',\n",
    "        'customer_tier', 'customer_spending_tier', 'customer_age_group'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    time_dimension = df[['order_date']].drop_duplicates().copy()\n",
    "    time_dimension['day'] = pd.to_datetime(time_dimension['order_date']).dt.day\n",
    "    time_dimension['month'] = pd.to_datetime(time_dimension['order_date']).dt.month\n",
    "    time_dimension['year'] = pd.to_datetime(time_dimension['order_date']).dt.year\n",
    "    time_dimension['quarter'] = pd.to_datetime(time_dimension['order_date']).dt.quarter\n",
    "    time_dimension['week'] = pd.to_datetime(time_dimension['order_date']).dt.isocalendar().week\n",
    "    time_dimension['day_of_week'] = pd.to_datetime(time_dimension['order_date']).dt.day_name()\n",
    "    time_dimension['is_weekend'] = time_dimension['day_of_week'].isin(['Saturday', 'Sunday'])\n",
    "    time_dimension['is_holiday'] = df.groupby('order_date')['is_festival_sale'].max().values\n",
    "    time_dimension['holiday_name'] = df.groupby('order_date')['festival_name'].first().values\n",
    "    time_dimension.rename(columns={'order_date': 'date'}, inplace=True)\n",
    "\n",
    "    # Load into MySQL\n",
    "    load_table(customers, \"customers\")\n",
    "    load_table(products, \"products\")\n",
    "    load_table(time_dimension, \"time_dimension\")\n",
    "    load_table(transactions, \"transactions\")\n",
    "\n",
    "# Create indexes\n",
    "index_queries = [\n",
    "    # Transactions\n",
    "    \"CREATE INDEX idx_order_date ON transactions(order_date);\",\n",
    "    \"CREATE INDEX idx_customer_id ON transactions(customer_id);\",\n",
    "    \"CREATE INDEX idx_product_id ON transactions(product_id);\",\n",
    "    \"CREATE INDEX idx_payment_method ON transactions(payment_method_cleaned);\",\n",
    "    \"CREATE INDEX idx_order_year_month ON transactions(order_year, order_month);\",\n",
    "    \"CREATE INDEX idx_return_status ON transactions(return_status);\",\n",
    "    # Products\n",
    "    \"CREATE INDEX idx_category_subcategory ON products(category, subcategory);\",\n",
    "    \"CREATE INDEX idx_brand ON products(brand);\",\n",
    "    \"CREATE INDEX idx_prime_eligible ON products(is_prime_eligible);\",\n",
    "    # Customers\n",
    "    \"CREATE INDEX idx_customer_location ON customers(customer_city, customer_state);\",\n",
    "    \"CREATE INDEX idx_customer_tier ON customers(customer_tier);\",\n",
    "    \"CREATE INDEX idx_spending_tier ON customers(customer_spending_tier);\",\n",
    "    # Time Dimension\n",
    "    \"CREATE INDEX idx_year_month ON time_dimension(year, month);\",\n",
    "    \"CREATE INDEX idx_day_of_week ON time_dimension(day_of_week);\",\n",
    "    \"CREATE INDEX idx_is_weekend ON time_dimension(is_weekend);\",\n",
    "    \"CREATE INDEX idx_is_holiday ON time_dimension(is_holiday);\"\n",
    "]\n",
    "\n",
    "for query in index_queries:\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        print(f\"üîß Index created: {query.split()[2]}\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"‚ö†Ô∏è Index creation failed: {err}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"üéâ All data loaded and indexed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4577bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# --- Configuration ---\n",
    "st.set_page_config(page_title=\"Database Viewer\", layout=\"wide\")\n",
    "\n",
    "# --- Secrets (stored in .streamlit/secrets.toml) ---\n",
    "db_user = st.secrets[\"amazon\"][\"root\"]\n",
    "db_password = st.secrets[\"amazon\"][\"Akshiya\"]\n",
    "db_host = st.secrets[\"amazon\"][\"localhost\"]\n",
    "db_port = st.secrets[\"amazon\"][\"3306\"]\n",
    "db_name = st.secrets[\"amazon\"][\"amazon\"]\n",
    "\n",
    "# --- Create Engine ---\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "\n",
    "# --- Load Data ---\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    query = \"SELECT * FROM your_table_name\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "# --- Streamlit UI ---\n",
    "st.title(\"üìä MySQL Database Viewer\")\n",
    "df = load_data()\n",
    "st.dataframe(df, use_container_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "import streamlit as st\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# --- Streamlit Page Config ---\n",
    "st.set_page_config(page_title=\"üìä Amazon MySQL Viewer\", layout=\"wide\")\n",
    "\n",
    "# --- Load Secrets ---\n",
    "db_user = st.secrets[\"amazon\"][\"root\"]\n",
    "db_password = st.secrets[\"amazon\"][\"Akshiya\"]\n",
    "db_host = st.secrets[\"amazon\"][\"localhost\"]\n",
    "db_port = st.secrets[\"amazon\"][\"3306\"]\n",
    "db_name = st.secrets[\"amazon\"][\"amazon\"]\n",
    "\n",
    "# --- Create SQLAlchemy Engine ---\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "\n",
    "# --- Connect to MySQL for Bulk Loading ---\n",
    "conn = mysql.connector.connect(\n",
    "    host=db_host,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    database=db_name,\n",
    "    allow_local_infile=True\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SET GLOBAL local_infile = 1;\")\n",
    "\n",
    "# --- CSV Paths ---\n",
    "csv_paths = {\n",
    "    year: f\"C:/Users/Akshiya George/OneDrive/Desktop/Data Science/Amazon/amazon_india_{year}.csv\"\n",
    "    for year in range(2015, 2026)\n",
    "}\n",
    "\n",
    "# --- Load Table Function ---\n",
    "def load_table(df, table_name):\n",
    "    temp_path = f\"{table_name}_temp.csv\"\n",
    "    df.to_csv(temp_path, index=False)\n",
    "    query = f\"\"\"\n",
    "    LOAD DATA LOCAL INFILE '{temp_path.replace(\"\\\\\", \"/\")}'\n",
    "    INTO TABLE {table_name}\n",
    "    FIELDS TERMINATED BY ',' \n",
    "    ENCLOSED BY '\"'\n",
    "    LINES TERMINATED BY '\\n'\n",
    "    IGNORE 1 ROWS;\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    os.remove(temp_path)\n",
    "    print(f\"‚úÖ Loaded {table_name}\")\n",
    "\n",
    "# --- Process Each CSV ---\n",
    "for year, path in csv_paths.items():\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    transactions = df[[\n",
    "        'transaction_id', 'order_date', 'customer_id', 'product_id',\n",
    "        'original_price_inr', 'discount_percent', 'discounted_price_inr',\n",
    "        'quantity', 'subtotal_inr', 'delivery_charges', 'final_amount_inr',\n",
    "        'payment_method', 'payment_method_cleaned', 'delivery_days',\n",
    "        'delivery_type', 'is_prime_member', 'is_festival_sale', 'festival_name',\n",
    "        'customer_rating', 'return_status', 'order_month', 'order_year',\n",
    "        'order_quarter', 'dup_key', 'dup_count', 'dup_status', 'flag_for_review'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    products = df[[\n",
    "        'product_id', 'product_name', 'category', 'subcategory', 'brand',\n",
    "        'product_weight_kg', 'is_prime_eligible', 'product_rating'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    customers = df[[\n",
    "        'customer_id', 'customer_city', 'customer_state',\n",
    "        'customer_tier', 'customer_spending_tier', 'customer_age_group'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    time_dimension = df[['order_date']].drop_duplicates().copy()\n",
    "    time_dimension['day'] = pd.to_datetime(time_dimension['order_date']).dt.day\n",
    "    time_dimension['month'] = pd.to_datetime(time_dimension['order_date']).dt.month\n",
    "    time_dimension['year'] = pd.to_datetime(time_dimension['order_date']).dt.year\n",
    "    time_dimension['quarter'] = pd.to_datetime(time_dimension['order_date']).dt.quarter\n",
    "    time_dimension['week'] = pd.to_datetime(time_dimension['order_date']).dt.isocalendar().week\n",
    "    time_dimension['day_of_week'] = pd.to_datetime(time_dimension['order_date']).dt.day_name()\n",
    "    time_dimension['is_weekend'] = time_dimension['day_of_week'].isin(['Saturday', 'Sunday'])\n",
    "    time_dimension['is_holiday'] = df.groupby('order_date')['is_festival_sale'].max().values\n",
    "    time_dimension['holiday_name'] = df.groupby('order_date')['festival_name'].first().values\n",
    "    time_dimension.rename(columns={'order_date': 'date'}, inplace=True)\n",
    "\n",
    "    load_table(customers, \"customers\")\n",
    "    load_table(products, \"products\")\n",
    "    load_table(time_dimension, \"time_dimension\")\n",
    "    load_table(transactions, \"transactions\")\n",
    "\n",
    "# --- Create Indexes ---\n",
    "index_queries = [\n",
    "    \"CREATE INDEX idx_order_date ON transactions(order_date);\",\n",
    "    \"CREATE INDEX idx_customer_id ON transactions(customer_id);\",\n",
    "    \"CREATE INDEX idx_product_id ON transactions(product_id);\",\n",
    "    \"CREATE INDEX idx_payment_method ON transactions(payment_method_cleaned);\",\n",
    "    \"CREATE INDEX idx_order_year_month ON transactions(order_year, order_month);\",\n",
    "    \"CREATE INDEX idx_return_status ON transactions(return_status);\",\n",
    "    \"CREATE INDEX idx_category_subcategory ON products(category, subcategory);\",\n",
    "    \"CREATE INDEX idx_brand ON products(brand);\",\n",
    "    \"CREATE INDEX idx_prime_eligible ON products(is_prime_eligible);\",\n",
    "    \"CREATE INDEX idx_customer_location ON customers(customer_city, customer_state);\",\n",
    "    \"CREATE INDEX idx_customer_tier ON customers(customer_tier);\",\n",
    "    \"CREATE INDEX idx_spending_tier ON customers(customer_spending_tier);\",\n",
    "    \"CREATE INDEX idx_year_month ON time_dimension(year, month);\",\n",
    "    \"CREATE INDEX idx_day_of_week ON time_dimension(day_of_week);\",\n",
    "    \"CREATE INDEX idx_is_weekend ON time_dimension(is_weekend);\",\n",
    "    \"CREATE INDEX idx_is_holiday ON time_dimension(is_holiday);\"\n",
    "]\n",
    "\n",
    "for query in index_queries:\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        print(f\"üîß Index created: {query.split()[2]}\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"‚ö†Ô∏è Index creation failed: {err}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"üéâ All data loaded and indexed successfully.\")\n",
    "\n",
    "# --- Streamlit UI ---\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    query = \"SELECT * FROM transactions\"  # Replace with your desired table\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "st.title(\"üìä Amazon MySQL Database Viewer\")\n",
    "df = load_data()\n",
    "st.dataframe(df, use_container_width=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
